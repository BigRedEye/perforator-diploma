\section{Введение}

\epigraph{
    \todo{These are not the droids you are looking for}
}{
    \todo{Obi-Wan Kenobi}
}

Масштабы и сложность существующих программных систем постоянно растут, зачастую экспоненциально.
Заметно увеличиваются расходы крупных компаний на серверные компоненты.
Размеры крупных вычислительных центров могут достигать нескольких сотен тысяч серверов.

При эксплуатации программных систем подобных размеров любые оптимизации исполняемого кода влекут значительную экономию ресурсов, оправдывающую время, затраченное программистами на оптимизацию и улучшение программы.
Однако, при работе над оптимизацией исходного кода (повышением эффективности утилизации тех или иных ресурсов, например, процессорных тактов на один запрос пользователя или использования памяти структурой данных).
Примером классической оптимизации может являться разработка и внедрение более эффективных и сложных структур данных и алгоритмов.
В то же время распространены и зачастую не менее полезны и более примитивные оптимизации, например, кеширование результатов выполнения тяжелых регионов программы.

\subsection{Актуальность}
Существует множество подходов в оптимизации кода, однако одним из наиболее эффективным на практике
является анализ программы при помощи профилировщика (profiler) --- специального инструмента, позволяющего оценить использование ресурсов программой, анализ результатов профилирования (зачастую при помощи специальных средств визуализации), и точечная оптимизация узких с точки зрения профилировщика мест.

Одной из важных проблем, ограничивающих применимость вышеописанного метода, является сложность воспроизведения реальной нагрузки на программу в тестовом окружении.
Например, часто оказывается, что копия программы, запущенная программистом на локальной машине заметно отличается по характеристикам производительности от той же программы, запущенной на вычислительном кластере.
Это происходит из-за целого ряда ограничений: 
\begin{itemize}
    \item Различия в вычислительных характеристиках серверов, выполняющих анализируемый код (производительность и особенности CPU, скорость доступа и пропускная способность RAM, характеристики дисковой и сетевой подсистем).
    \item Сложность воспроизведения реальной нагрузки. Например, для тестирования производительности веб-сервера необходимо собрать большое количество реальных запросов и выполнить их заново с тем же распределением по времени.
    \item Отличия в программном обеспечении между реальным окружением и тестовым стендом (версии и особенности OS, версии драйверов и микрокода).
    \item Особенности архитектуры облака. В современных облаках используется большое количество систем контейнеризации и виртуализации, позволяющих выполнять программы от разных пользователей в полной изоляции друг от друга, квотировать использование ресурсов, надежно контролировать выполнение пользовательских процессов и управлять ими.
    \item Отличия между версиями программного обеспечения, анализируемого разработчиком и версиями программы в реальном окружении. Например, зачастую код, исполняемый под реальной нагрузкой, компилируется с использованием link time optimization \todo{ref}: крайне дорогостоящий процесс оптимизации кода во время компоновки. Использование LTO заметно меняет профиль исполнения кода, однако сборка с LTO занимает заметно больше времени (вплоть до десятков минут) по сравнению с обычной оптимизированной сборкой. Программисту намного удобнее проводить короткие итерации экспериментов с использованием обычной оптимизированной сборки, однако усложняется интерпретация результатов.
\end{itemize}
Более того, профиль нагрузки может отличаться и между разными машинами в облаке по вышеописанным причинам: например, в том случае, если у серверов отличается набор комплектующих или версии OS.

Кроме того, процесс профилирования зачастую требует много времени разработчика: необходимо собрать тестовый стенд, удостовериться в его репрезентативности, провести тест приложения на производительность и записать результаты профилирования, после чего проанализировать их. Данный процесс часто занимает десятки минут, при этом легко пропустить какую-то из деталей и получить нерелевантный профиль.

В связи с вышеописанными проблемами все больше интереса вызывают методы для анализа производительности программ наживую, под реальной нагрузкой и без использования тестовых стендов.

\subsection{Цели и задачи}
В процессе дипломной работы решалась задача разработки и внедрения сервиса распределенного профилировщика с рабочим названием Perforator в компании Яндекс.
Perforator должен стать единственным массовым решением для анализа производительности в компании, автоматически подключиться к тысячам существующих сервисов, позволить разработчикам без сложного процесса настройки автоматически получить точные профили использования важных ресурсов (в первую очередь, тактов процессора).

Использование массового профилировщика с низким порогом входа заметно повысить утилизацию ресурсов, сократить время ответа сервисов пользователям, повысить прозрачность использования ресурсов внутри компании, собрать бесценную статистику стоимости и частоты использования различных библиотек.
