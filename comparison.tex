\section{Существующие решения}
Задача профилирования не нова.
Профилировщики разного уровня сложности существовали с самой зари программирования.
Рассмотрим некоторые важные для постановки задачи существующие решения, проанализируем их подходы.

\subsection{Метрики}
При оптимизации программ крайне важно сформулировать метрику, которую планируется улучшить.
Для разных видов метрик существуют различные решения для профилирования. Можно выделить несколько наиболее востребованных метрик.

\subsubsection{Реальное время}
Wall time. Программа, использующая меньше реального времени, быстрее генерирует результат и быстрее отвечает пользователю. Для оптимизации реального времени, например, убирают лишние взаимодействия с дисковой или сетевой подсистемами, делают их асинхронными, избавляются от тяжелых взаимных блокировок потоков, повышают утилизацию вычислительных мощностей, разбивают однопоточные вычисления на несколько потоков.

\subsubsection{Процессорное время}
CPU time. Оптимизация CPU time в общем случае отличается от оптимизации Wall time.
Часто повышение пропускной способности системы понижает ее отзывчивость, и наоборот.
В то же время, некоторые оптимизации позволяют сэкономить и CPU time, и Wall time, например, использование более эффективных однопоточных алгоритмов.
Система, потребляющая меньше количество CPU time, более экономна и позволяет обработать больше запросов за единицу времени.
В рамках данной работы рассматривается в первую очередь оптимизация процессорного времени.

\subsubsection{Анонимная память}
Анализ использования оперативной памяти программой зачастую не менее важен, чем анализ использования CPU.
К сожалению, в отличие от CPU time и Wall time, использование анонимной оперативной памяти
отлаживать достаточно сложно. Современные программы используют нетривиальные аллокаторы
в качестве прослойки между пользовательским кодом и операционной системой, скрывающие большое
количество нюансов при работе с памятью и эффективно переиспользующих регионы памяти.

Существует ряд удобных инструментов для анализа использования памяти \cite{valgrind} \cite{gperftools} \cite{tcmalloc:hp}, однако
применяемые там техники достаточно специальны и мало применимы в нашем случае.

\subsubsection{Низкоуровневые события}
Широко распространенные архитектуры процессоров (x86-64, ARM, IBM POWER9, RISC-V и другие)
поддерживают механизмы эффективного получения различных счетчиков производительности
напрямую с процессора при помощи особого набора инструкций.
Устройство, отвечающее за отслеживание и обработку событий, известно как Performance Monitoring Unit (PMU).

В качестве счетчиков могут выступать произвольные события, интересные инженерам.
Например, количество тактов процессора, количество промахов кеша второго уровня или количество
инструкций ветвления, предугаданных механизмом предсказания ветвлений.
Кроме того, зачастую поддерживается механизм семплирования \cite{linux:pmi}, при котором процессор генерирует
особое прерывание при переполнении счетчика. Ядро операционной системы обрабатывает
данное прерывание и анализирует состояние системы на момент прерывания.

Данный механизм позволяет получать статистическое приближение реального распределения использования тех или иных ресурсов.

\subsection{Инструментирующие профилировщики}
Одной из базовых идей профилирования является \textit{инструментирование}. Данный способ требует особого режима компиляции, в котором компилятор особым образом дополняет машинный код, чтоб обеспечить работу профилировщика. Одним из наиболее известных инструментирующих профилировщиков является gprof.

\subsubsection{gprof}
gprof \cite{gprof} – профилировщик для Unix-подобных систем. Совместимые с gprof компиляторы генерируют вызов специальной функции \lstinline!mcount! в начале вызова каждой функции \cite{gprof:mcount}. При запуске программы код профилировщика собирает полную информацию об вызываемых функциях и сохраняет в файл для дальнейшего анализа.
gprof поддерживает два вида профилей:
\begin{enumerate}
    \item <<Плоский>> профиль: распределение времени выполнения по различным функциям.
    \item Стек вызовов: для каждого вызова функции gprof собирает список родительских стековых кадров, что позволяет отслеживать зависимости при вызовах. На практике данный профиль намного полезнее плоского, так как позволяет анализировать структуру программы и находить узкие места в промежуточных функциях. Большинство современных инструментов профилирования так или иначе собирает подобные профили.
\end{enumerate}

Основным недостатком данного подхода является требование к инструментации кода, а так же значительное замедление программы. Каждый вызов функции замедляется из-за необходимости записать необходимую для профиля информацию, а результаты профилирования искажаются: реальное время выполнения функции без использования профилировщика ниже, что особенно заметно на небольших функциях. Кроме того, gprof не позволяет собрать профиль для анализа CPU time, что является одним из наиболее востребованных способов использования профилировщиков.

Из-за необходимости использования особого режима сборки разработчик почти всегда ограничен в использовании профилировщика только локальными запусками.

Современная версия gprof поддерживает режим семплирующего профилировщика.
При помощи системного вызова \lstinline!setitimer! анализируемая программа настраивает регулярную доставку сигнала \lstinline!SIGALRM!, собирая информацию об состоянии программы в момент получения сигнала при помощи нетривиального обработчика сигнала. Однако, подобный способ все так же требует инструментации исходного кода, а так же достаточно тяжел при использовании.

Подход gprof был прорывным для своего времени.
Инструмент до сих пор достаточно популярен и развивается, несмотря на наличие более современных решений.

\todo{Картинка выхлопа pprof}

\todo{\subsubsection{coz profiler}}


\subsection{Семплирующие профилировщики}
Наиболее широко распространенный класс профилировщиков – \textit{семплирующие профилировщики}.
Данный подход предполагает сбор набора \textit{семплов} – снимков состояния программы.
Часто семплы снимают через равные промежутки времени или равное число анализируемых событий.

\todo{\subsubsection{Poor man's profiler}}
\todo{Про gdb, gdb со скриптом, статья на хабре про БК}

\todo{\subsubsection{pprof}}
\todo{Про Go}

\todo{\subsubsection{Intel PMU}}
\todo{Про прерывания, виды событий, какая крутая технология}

\todo{\subsubsection{Linux perf}}
\todo{Про perf\_event\_open, ...}

\todo{\subsubsection{Google Cloud Profiler}}

\todo{\subsubsection{Google Wide Profiler}}

\todo{\subsubsection{Pyroscope}}

\todo{\subsubsection{Parca}}

\subsection{Комбинированные решения}

\todo{\subsubsection{Intel VTune}}

\todo{\subsubsection{Valgrind}}

\subsection{Flamegraph}
\todo{Про флеймграфы и применения}

\subsection{Раскрутка стеков}
\todo{\subsubsection{Frame pointers}}
\todo{\subsubsection{Исключения}}

\todo{\subsection{DWARF}}

\subsection{eBPF}
\todo{Про eBPF и пользу, про bcc}
